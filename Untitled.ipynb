{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45455343",
   "metadata": {},
   "source": [
    "### USFSA Results Scraping V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69752e9",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc939292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc0d0d",
   "metadata": {},
   "source": [
    "#### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918d2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Create a lookup table for all competition URLs\n",
    "main_url = \"https://ijs.usfigureskating.org/leaderboard/nonqual_results/2022/32007/index.html\"\n",
    "\n",
    "# TODO \n",
    "# Update lookup table with all possible group sizes\n",
    "lookup = {13: [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 1],\n",
    "          12: [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "          11: [12, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "          10: [12, 10, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "          9: [12, 10, 8, 6, 5, 4, 3, 2, 1],\n",
    "          8: [12, 10, 8, 6, 4, 3, 2, 1],\n",
    "          7: [12, 10, 8, 6, 4, 2, 1],\n",
    "          6: [12, 10, 8, 6, 4, 2],\n",
    "          5: [10, 8, 6, 4, 2],\n",
    "          4: [8, 6, 4, 2],\n",
    "          3: [6, 4, 2],\n",
    "          2: [6, 4],\n",
    "          1: [6]\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13a6ee",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f622a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the main page\n",
    "def parse_main(url):\n",
    "    \n",
    "    '''\n",
    "    Takes a USFSA url containing pages of results and \n",
    "    extracts the links from each individual page\n",
    "    \n",
    "    :param url: A url corresponding to a main results page\n",
    "    :returns: A list of webpages stemming from the main results \n",
    "    page\n",
    "    '''\n",
    "    \n",
    "    # Helper function to extract links\n",
    "    def _extract_link(x):\n",
    "        return x.find(\"a\")[\"href\"]\n",
    "    \n",
    "    request = requests.get(url)\n",
    "    \n",
    "    # Important variables to store\n",
    "    soup   = bs4.BeautifulSoup(request.text)\n",
    "    events = soup.find_all(\"td\", attrs = {\"rowspan\": 1})\n",
    "    links  = soup.find_all(\"td\", attrs = {\"class\": \"cm rb\"})\n",
    "    \n",
    "    # Extract the url ends for each webpage\n",
    "    ends = list(map(_extract_link, links))\n",
    "\n",
    "    # Request urls for each webpage\n",
    "    baseurl  = url.replace(\"index.html\", \"\")\n",
    "    webpages = [baseurl + i for i in ends]\n",
    "    \n",
    "    return webpages, events\n",
    "\n",
    "    \n",
    "\n",
    "# Function to parse each results page\n",
    "def parse_results(html, team = False):\n",
    "    \n",
    "    '''\n",
    "    Takes an html text object containing the results of\n",
    "    one group\n",
    "    \n",
    "    :param html: html text\n",
    "    :param team: A boolean stating whether or not the event is a team \n",
    "    maneuvers event\n",
    "    :returns: A DataFrame containing the place and university\n",
    "    for each start\n",
    "    '''\n",
    "    \n",
    "    # Create a soup object and extract the rows of the results table\n",
    "    soup = bs4.BeautifulSoup(html.text)\n",
    "    res  = soup.find_all(\"td\", attrs = {\"colspan\":1})\n",
    "    rows = soup.find_all(\"tr\")\n",
    "    rows = [x for x in rows if (len(x.find_all(\"td\")) == 9 or len(x.find_all(\"td\")) == 7)]\n",
    "    \n",
    "    # Extract the University names from each page\n",
    "    out = []\n",
    "    for i, x in enumerate(res):\n",
    "        if team:\n",
    "            uni = x.text\n",
    "        else:\n",
    "            uni = x.text.split(\", \")[-1]\n",
    "        out.append([rows[i].find(\"td\").text, uni, rows[i].find_all(\"td\")[-1].text])\n",
    "        \n",
    "    return pd.DataFrame(out, columns = [\"Place\", \"College\", \"Tie\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to parse all of the results and remove withdrawals\n",
    "def format_results(webpages):\n",
    "    \n",
    "    '''\n",
    "    Takes a list of webpages and converts each results page to\n",
    "    a DataFrame\n",
    "    \n",
    "    :param webpages: A list of webpage urls\n",
    "    :returns: A list of DataFrames for each set of results\n",
    "    '''\n",
    "    \n",
    "    DFS = []\n",
    "    for i, x in enumerate(webpages):\n",
    "        temp = requests.get(x)\n",
    "        try:\n",
    "            data = parse_results(temp)\n",
    "            data = data.loc[~data[\"Tie\"].str.contains(\"Withdraw\")]\n",
    "            DFS.append(data)\n",
    "        except:\n",
    "            pass\n",
    "    return DFS\n",
    "\n",
    "\n",
    "# Function to assign points for each event and totals for each team\n",
    "def assign_points(DFS):\n",
    "    \n",
    "    '''\n",
    "    Takes a list of DataFrames from format_results and totals the\n",
    "    points for each collegiate team\n",
    "    \n",
    "    :param DFS: A list of results DataFrames\n",
    "    :returns: A Series containing the point totals for each team\n",
    "    at the current point in the competition\n",
    "    '''\n",
    "    \n",
    "    OUT = []\n",
    "    for i, x in enumerate(DFS):\n",
    "        num = len(x)\n",
    "\n",
    "        # Assign a number of points to each column\n",
    "        x = x.assign(points = lookup[num])\n",
    "\n",
    "        # Handle ties\n",
    "        temp = x.groupby(\"Place\")[\"points\"].transform(lambda x: x.mean())\n",
    "        x = x.assign(points = temp)\n",
    "\n",
    "        # Handle championship event edge case\n",
    "        if \"Championship\" in events[i].text or \"International\" in events[i].text:\n",
    "            x[\"points\"] = x[\"points\"] + 2\n",
    "\n",
    "        OUT.append(x)\n",
    "        \n",
    "    FULL = pd.concat(OUT)\n",
    "    \n",
    "    return FULL.groupby(\"College\")[\"points\"].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35f06f",
   "metadata": {},
   "source": [
    "#### Running Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bad7d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "College\n",
       "Univ. of CA Los Angeles     218.0\n",
       "University of Denver        214.0\n",
       "Univ. of CA Berkeley        193.0\n",
       "Univ. of CA San Diego       176.0\n",
       "Arizona State University    131.0\n",
       "Stanford University         127.5\n",
       "Univ. of CO Boulder         103.0\n",
       "CO State University          79.5\n",
       "Univ. of CO COSpgs           65.0\n",
       "Utah State University        63.0\n",
       "Colorado College             59.0\n",
       "Univ. of CA Irvine           38.0\n",
       "Western WA Univ.             27.0\n",
       "Univ. of Northern CO         17.0\n",
       "University of Wyoming        16.0\n",
       "Name: points, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpages, events = parse_main(main_url)\n",
    "\n",
    "results  = format_results(webpages)\n",
    "totals   = assign_points(results)\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9ecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
